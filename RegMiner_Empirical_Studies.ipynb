{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YbcqCeDZv4d"
   },
   "source": [
    "# RegMiner Empirical Studies\n",
    "\n",
    "This file contains the script that was used for the empirical study of the RegMiner. To run the script locally, ```git``` needs to be present on the machine. This is required to get the commit history of the different repository. In addition, the relevant repositories should also be downloaded from GitHub. A compilation of the repository for the 537 bugs can be found [here](?).\n",
    "\n",
    "All of these dependencies can been fulfilled by this Colab session and the code can run as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghEUqdWBZ3us"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Nqm6jKB1Z0sa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, contextlib, re, subprocess\n",
    "from datetime import datetime\n",
    "from difflib import Differ, SequenceMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wAWYsLuZ6yB"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lQlp69ZQZ-lF"
   },
   "outputs": [],
   "source": [
    "# Reference from https://stackoverflow.com/questions/431684/equivalent-of-shell-cd-command-to-change-the-working-directory\n",
    "@contextlib.contextmanager\n",
    "def change_dir(directory):\n",
    "    current_dir= os.getcwd()\n",
    "    try: \n",
    "        os.chdir(directory)\n",
    "        yield\n",
    "    finally: os.chdir(current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anAlqAkQksN1"
   },
   "source": [
    "### Basic retrieval of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CgBMpG2naBiD"
   },
   "outputs": [],
   "source": [
    "def get_log(directory, commit):\n",
    "    with change_dir(directory):\n",
    "        log = os.popen(f\"git log --pretty=oneline {commit} -1\").read()\n",
    "        return log\n",
    "\n",
    "def get_num_commits(directory, commit):\n",
    "    with change_dir(directory):\n",
    "        return int(os.popen(f\"git rev-list --count {commit}\").read())\n",
    "\n",
    "def get_author_date(directory, commit):\n",
    "    with change_dir(directory):\n",
    "        raw_time = os.popen(f\"git show {commit} -s --format=%ad\").read().strip()\n",
    "        cleaned_time = datetime.strptime(raw_time, \"%a %b %d %H:%M:%S %Y %z\")\n",
    "        return cleaned_time\n",
    "\n",
    "def diff_in_commits(directory, new_commit, old_commit):\n",
    "    return abs(get_num_commits(directory, new_commit) - get_num_commits(directory, old_commit))\n",
    "\n",
    "def diff_in_time(directory, new_commit, old_commit):\n",
    "    time_difference = get_author_date(directory, new_commit) - get_author_date(directory, old_commit)\n",
    "    return abs(time_difference).total_seconds() / (24 * 60 * 60) # get in terms of days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05FkasbVkwpe"
   },
   "source": [
    "### Advance retrieval of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "mphuDN4QaD9r"
   },
   "outputs": [],
   "source": [
    "def statistics(directory, new_commit, old_commit=None, file=None):\n",
    "    \"\"\"\n",
    "    If an old_commit is not specified, by default, the commit will be compared with the previous commit\n",
    "    If a file is specified, it will compare the differences between the two files.\n",
    "    Else, it will compare all files across two directories and return\n",
    "    (number_files_modified, lines_added, lines_deleted)\n",
    "    \"\"\"\n",
    "    if old_commit is None: old_commit = f\"{new_commit}~1\"\n",
    "    with change_dir(directory):\n",
    "        if file is None:\n",
    "            stats = os.popen(f\"git diff --shortstat {old_commit} {new_commit}\").read()\n",
    "        else:\n",
    "            stats = os.popen(f\"git diff --shortstat {old_commit} {new_commit} -- {file}\").read()\n",
    "        group = re.search(r\"\\d+\", stats)\n",
    "        files = 0 if group is None else int(group[0])\n",
    "        group = re.search(r\"\\d+(?= insertion)\", stats)\n",
    "        insertions = 0 if group is None else int(group[0])\n",
    "        group = re.search(r\"\\d+(?= deletion)\", stats)\n",
    "        deletions = 0 if group is None else int(group[0])\n",
    "        return (files, insertions, deletions)\n",
    "\n",
    "def files_changed(directory, new_commit, old_commit=None):\n",
    "    \"\"\"\n",
    "    Return all files that are different between two commits.\n",
    "    By default, if old_commit is not defined, compare with the previous commit.\n",
    "    \"\"\"\n",
    "    if old_commit is None: old_commit = f\"{new_commit}~1\"\n",
    "    with change_dir(directory):\n",
    "        results = os.popen(f\"git diff --raw --minimal {old_commit} {new_commit}\").readlines()\n",
    "        files = [re.search(r\"[\\S]*\\.\\w*\", result) for result in results]\n",
    "        files = [file[0] for file in files if file is not None]\n",
    "        return files\n",
    "\n",
    "def hunks_changed(directory, new_commit, old_commit=None):\n",
    "    \"\"\"\n",
    "    Return all hunks changed as a dictionary with the following details.\n",
    "    It is possible for method_name to be none if no appropriate method name is found.\n",
    "    \"\"\"\n",
    "    if old_commit is None: old_commit = f\"{new_commit}~1\"\n",
    "    files = files_changed(directory, new_commit, old_commit)\n",
    "    hunks = []\n",
    "    with change_dir(directory):\n",
    "        for file in files:\n",
    "            output = subprocess.run(f\"git diff -U1000 {old_commit} {new_commit} -- {file}\",\n",
    "                                    shell=True, capture_output=True).stdout.decode(errors=\"ignore\")\n",
    "            outputs = output.splitlines()\n",
    "            outputs = [output for output in outputs if len(output.strip()) > 0]\n",
    "            was_hunk = False\n",
    "            for i, output in enumerate(outputs):\n",
    "                if not re.search(r\"^[-+](?![-+])\", output):\n",
    "                    was_hunk = False\n",
    "                    continue\n",
    "                if not was_hunk:\n",
    "                    method_name = None\n",
    "                    index = i\n",
    "                    while index >= 0:\n",
    "                        target = outputs[i]\n",
    "                        if re.search(r\"(private|protected|static|public)\", target):\n",
    "                            method_name = re.search(r\"\\w+\\s*(?=[({])\", target)\n",
    "                        if method_name:\n",
    "                            method_name = method_name[0].strip()\n",
    "                            break\n",
    "                        index -= 1\n",
    "                    hunk_details = {\"FileName\": file,\n",
    "                                    \"MethodName\": method_name,\n",
    "                                    \"IndexStart\": i,\n",
    "                                    \"IndexEnd\": i,\n",
    "                                    \"Hunk\": [],\n",
    "                                    \"+\": [],\n",
    "                                    \"-\": []}\n",
    "                    hunks.append(hunk_details)\n",
    "                    prev_hunk = hunk_details\n",
    "                    was_hunk = True\n",
    "                else:\n",
    "                    prev_hunk = hunks[-1]\n",
    "                    prev_hunk[\"IndexEnd\"] = i\n",
    "                    prev_hunk[\"Hunk\"].append(output)\n",
    "                    prev_hunk[output[0]].append(output[1:].strip())\n",
    "        return hunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyzSlOxLk0Q3"
   },
   "source": [
    "### Scoring systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "QrFkD6AnlO79"
   },
   "outputs": [],
   "source": [
    "def compare_similarity(hunk1, hunk2):\n",
    "    min_len = min(len(hunk1), len(hunk2)) \n",
    "    if min_len < 3: # we do not bother with too small changes\n",
    "        return 0\n",
    "\n",
    "    d = Differ()\n",
    "    hunk1 = [line + \"\\n\" for line in hunk1]\n",
    "    hunk2 = [line + \"\\n\" for line in hunk2]\n",
    "    result = list(d.compare(hunk1, hunk2))\n",
    "    match_count, similar_count = 0, 0\n",
    "    for line in result:\n",
    "        label = line[0]\n",
    "        if label == \"+\" or label == \"-\": continue\n",
    "        if label == \"?\" and re.search(r\"\\^\", line) is not None:\n",
    "            similar_count += 1\n",
    "        else:\n",
    "            match_count += 1\n",
    "    return (match_count + (similar_count/2)) / min_len\n",
    "\n",
    "def get_refactor_scores(hunks):\n",
    "    scores = []\n",
    "    for hunk in hunks:\n",
    "        add = hunk[\"+\"]\n",
    "        max_score = 0\n",
    "        hunk_ext = re.search(r\"\\.w+\", hunk[\"FileName\"])\n",
    "        if hunk_ext is not None: hunk_ext = hunk_ext[0]\n",
    "        for h in hunks:\n",
    "            h_ext = re.search(r\"\\.w+\", h[\"FileName\"])\n",
    "            if h_ext is not None: h_ext = h_ext[0]\n",
    "            if h == hunk or hunk_ext != h_ext: continue\n",
    "            delete = h[\"-\"]\n",
    "            max_score = max(compare_similarity(add, delete), max_score)\n",
    "            scores.append(max_score)\n",
    "    return scores\n",
    "\n",
    "def revert_index(hunks1, hunks2):\n",
    "    revert_indexes = []\n",
    "    for hunk1 in hunks1:\n",
    "        for hunk2 in hunks2:\n",
    "            if hunk1[\"FileName\"] != hunk2[\"FileName\"]:\n",
    "                continue\n",
    "            revert_count = 0\n",
    "            for line in hunk1[\"+\"]:\n",
    "                if line in hunk2[\"-\"]:\n",
    "                    revert_count += 1\n",
    "            for line in hunk1[\"-\"]:\n",
    "                if line in hunk2[\"+\"]:\n",
    "                    revert_count += 1\n",
    "            lines_changed = len(hunk1[\"Hunk\"])\n",
    "            revert_index = revert_count / lines_changed if lines_changed > 0 else 0\n",
    "            revert_indexes.append(revert_index)\n",
    "    return sum(revert_indexes)/len(revert_indexes) if len(revert_indexes) > 0 else 0\n",
    "\n",
    "def distances_to_fix(hunks1, hunks2):\n",
    "    distances = []\n",
    "    for h1 in hunks1:\n",
    "        for h2 in hunks2:\n",
    "            file1 = h1[\"FileName\"]\n",
    "            file2 = h2[\"FileName\"]\n",
    "            method1 = h1[\"MethodName\"]\n",
    "            method2 = h2[\"MethodName\"]\n",
    "            hs1, he1 = h1[\"IndexStart\"], h1[\"IndexEnd\"]\n",
    "            hs2, he2 = h2[\"IndexStart\"], h2[\"IndexEnd\"]\n",
    "            if file1 != file2 and SequenceMatcher(None, file1, file2).ratio() < 0.8:\n",
    "                distances.append(3)\n",
    "            elif method1 != method2 and (method1 is None or method2 is None or SequenceMatcher(None, method1, method2).ratio() < 0.8):\n",
    "                distances.append(2)\n",
    "            elif he1 < hs2 or he2 < hs2:\n",
    "                distances.append(1)\n",
    "            else:\n",
    "                distances.append(0)\n",
    "    return (min(distances), max(distances), 0 if len(distances) == 0 else sum(distances)/len(distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6wyiqVmk75K"
   },
   "source": [
    "### Advance boolean functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "COYEhOUNrZNs"
   },
   "outputs": [],
   "source": [
    "def is_bug_fix(directory, commit):\n",
    "    log = get_log(directory, commit).lower()\n",
    "    return re.search(r\"(issue|fix|revert|bug)\\w*\", log) is not None\n",
    "\n",
    "def is_refactor(directory, commit, scores):\n",
    "    log = get_log(directory, commit).lower()\n",
    "    if re.search(r\"refactor\", log):\n",
    "        return True\n",
    "    if len(scores) == 0 or max(scores) < 0.7:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def is_feature_enhancement(hunks, scores):\n",
    "    total_add, total_delete = 0, 0\n",
    "    for score, hunk in zip(scores, hunks):\n",
    "        if score >= 0.7:\n",
    "            continue # this is a refactored hunk\n",
    "        add_len = len(hunk[\"+\"])\n",
    "        del_len = len(hunk[\"-\"])\n",
    "        if add_len > 10 and (del_len == 0 or add_len/del_len > 3):\n",
    "            return True\n",
    "        total_add += add_len\n",
    "        total_delete += del_len\n",
    "    return True if total_add > 20 and (total_delete == 0 or total_add / total_delete > 3) else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0r20BYlqaNsV"
   },
   "source": [
    "## Experiments\n",
    "\n",
    "First, we will retrieve the data from the relevant websites. A copy of the data can be found [here](https://www.dropbox.com/s/0aoi3ewxtr2xfvx/empirical_studies.tar.xz?dl=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SBTjrxBjaVxF"
   },
   "outputs": [],
   "source": [
    "#!wget -nv -O data.tar.xz \"https://www.dropbox.com/s/0aoi3ewxtr2xfvx/empirical_studies.tar.xz?dl=1\" && tar -xf data.tar.xz && rm data.tar.xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-X50ZyeS_p-n"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"empirical_studies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uzenN6ZE_uhz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project_Name</th>\n",
       "      <th>BFC_Commit</th>\n",
       "      <th>BIC_Commit</th>\n",
       "      <th>Working_Commit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app-maven-plugin</td>\n",
       "      <td>6ff4ae8fbe8c8b37b75a1893c48c7ad2b23552bc</td>\n",
       "      <td>8effcb6b0400f2023505542d0e8a2b01877a9577</td>\n",
       "      <td>53580a805b2acbde6fb968cbadd8a6763c55034b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app-maven-plugin</td>\n",
       "      <td>f1f709ea31c57c6378806e608b342fe0249c39d3</td>\n",
       "      <td>8effcb6b0400f2023505542d0e8a2b01877a9577</td>\n",
       "      <td>53580a805b2acbde6fb968cbadd8a6763c55034b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aviator</td>\n",
       "      <td>1895817d540479ea079ea433a0cf2aff53b5fbaa</td>\n",
       "      <td>e335bf1b5e17ebc5e549b9cecc4e73c243d4db3b</td>\n",
       "      <td>0ca42184fa0b21338296fd15d71d6e3aee3a80db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aviator</td>\n",
       "      <td>af3739881c0ec0c250f75fe9fb6a530e1ba068db</td>\n",
       "      <td>121881f2052a71e824f9de415cfdd457a1c513b9</td>\n",
       "      <td>62229076b9759c91ebecee9c8a2a83621c5b5ba3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aviator</td>\n",
       "      <td>afc9c4648510ce4279d470a4bf9aad356418d01c</td>\n",
       "      <td>e335bf1b5e17ebc5e549b9cecc4e73c243d4db3b</td>\n",
       "      <td>0ca42184fa0b21338296fd15d71d6e3aee3a80db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>verdict</td>\n",
       "      <td>17dd7ac9bcf687e81e353bc24bc2ea9520e45db1</td>\n",
       "      <td>b6ebb975cacd197691ca487055372fa9447d28da</td>\n",
       "      <td>1248c63d7c8773ceb5ffd92a4dd1486c3f893710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>verdict</td>\n",
       "      <td>6e11c2bdacdc986db619692cd204898a975e454f</td>\n",
       "      <td>6e775e54370dbd1a0a9393057695af3190131a25</td>\n",
       "      <td>d1ba53707e0147e3932a0d409b0081c91fb7fe06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>zip4j</td>\n",
       "      <td>13c170672da595561163804dc62451dc21bfc870</td>\n",
       "      <td>d5c5b413a2996bceb65db4adfd353030baf21d94</td>\n",
       "      <td>7be1b0620bf9dbb4c023a1682698ac5436b41fad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>zip4j</td>\n",
       "      <td>3f15884e338fd2490bb9ee710cf0828aca55d285</td>\n",
       "      <td>c158768c2880615bae983789690b5713e8de6794</td>\n",
       "      <td>e849b62bb94b506de8e76cdc7f0164d7fc145608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>zt-exec</td>\n",
       "      <td>0fe15955561ce3f6a90263b9b6f5d9bde27019a6</td>\n",
       "      <td>d9e4fdf61d15ab7492b6bdf40376536aebaaf6ff</td>\n",
       "      <td>8f20c555855f0f7a31c18de5490747a34f33aa7d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Project_Name                                BFC_Commit  \\\n",
       "0    app-maven-plugin  6ff4ae8fbe8c8b37b75a1893c48c7ad2b23552bc   \n",
       "1    app-maven-plugin  f1f709ea31c57c6378806e608b342fe0249c39d3   \n",
       "2             aviator  1895817d540479ea079ea433a0cf2aff53b5fbaa   \n",
       "3             aviator  af3739881c0ec0c250f75fe9fb6a530e1ba068db   \n",
       "4             aviator  afc9c4648510ce4279d470a4bf9aad356418d01c   \n",
       "..                ...                                       ...   \n",
       "532           verdict  17dd7ac9bcf687e81e353bc24bc2ea9520e45db1   \n",
       "533           verdict  6e11c2bdacdc986db619692cd204898a975e454f   \n",
       "534             zip4j  13c170672da595561163804dc62451dc21bfc870   \n",
       "535             zip4j  3f15884e338fd2490bb9ee710cf0828aca55d285   \n",
       "536           zt-exec  0fe15955561ce3f6a90263b9b6f5d9bde27019a6   \n",
       "\n",
       "                                   BIC_Commit  \\\n",
       "0    8effcb6b0400f2023505542d0e8a2b01877a9577   \n",
       "1    8effcb6b0400f2023505542d0e8a2b01877a9577   \n",
       "2    e335bf1b5e17ebc5e549b9cecc4e73c243d4db3b   \n",
       "3    121881f2052a71e824f9de415cfdd457a1c513b9   \n",
       "4    e335bf1b5e17ebc5e549b9cecc4e73c243d4db3b   \n",
       "..                                        ...   \n",
       "532  b6ebb975cacd197691ca487055372fa9447d28da   \n",
       "533  6e775e54370dbd1a0a9393057695af3190131a25   \n",
       "534  d5c5b413a2996bceb65db4adfd353030baf21d94   \n",
       "535  c158768c2880615bae983789690b5713e8de6794   \n",
       "536  d9e4fdf61d15ab7492b6bdf40376536aebaaf6ff   \n",
       "\n",
       "                               Working_Commit  \n",
       "0    53580a805b2acbde6fb968cbadd8a6763c55034b  \n",
       "1    53580a805b2acbde6fb968cbadd8a6763c55034b  \n",
       "2    0ca42184fa0b21338296fd15d71d6e3aee3a80db  \n",
       "3    62229076b9759c91ebecee9c8a2a83621c5b5ba3  \n",
       "4    0ca42184fa0b21338296fd15d71d6e3aee3a80db  \n",
       "..                                        ...  \n",
       "532  1248c63d7c8773ceb5ffd92a4dd1486c3f893710  \n",
       "533  d1ba53707e0147e3932a0d409b0081c91fb7fe06  \n",
       "534  7be1b0620bf9dbb4c023a1682698ac5436b41fad  \n",
       "535  e849b62bb94b506de8e76cdc7f0164d7fc145608  \n",
       "536  8f20c555855f0f7a31c18de5490747a34f33aa7d  \n",
       "\n",
       "[537 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressions = pd.read_csv(\"regressions.csv\")\n",
    "regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixIwwuOG_2oY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of past records: 440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████▌     | 496/537 [03:04<01:36,  2.35s/it]warning: inexact rename detection was skipped due to too many files.\n",
      "warning: you may want to set your diff.renameLimit variable to at least 2112 and retry the command.\n",
      "warning: inexact rename detection was skipped due to too many files.\n",
      "warning: you may want to set your diff.renameLimit variable to at least 2112 and retry the command.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    results = pd.read_csv(\"Intermediate_Result.csv\")\n",
    "except FileNotFoundError:\n",
    "    results = pd.DataFrame(columns=[\"Project\", \"BFC\", \"BIC\", \"Commits_Between\", \"Time_Between\",\n",
    "                                    \"BIC_Files_Edited\", \"BIC_Lines_Added\", \"BIC_Lines_Deleted\",\n",
    "                                    \"BFC_Files_Edited\", \"BFC_Lines_Added\", \"BFC_Lines_Deleted\",\n",
    "                                    \"BIC_Num_Hunks\", \"BFC_Num_Hunks\",\n",
    "                                    \"Min_Distance_Fix\", \"Max_Distance_Fix\", \"Mean_Distance_Fix\",\n",
    "                                    \"BIC_Is_Bug_Fix\", \"BIC_Is_Refactor\", \"BIC_Is_Feature_Enhancement\",\n",
    "                                    \"BFC_Is_Refactor\", \"BFC_Is_Feature_Enhancement\", \"Revert_Index\"])\n",
    "print(f\"Number of past records: {len(results)}\")\n",
    "\n",
    "for i, row in tqdm(regressions.iterrows(), total=len(regressions)):\n",
    "    if i < len(results):\n",
    "        continue\n",
    "    result = {}\n",
    "    directory = f\"repos/{row.Project_Name}\"\n",
    "    result[\"Project\"] = row.Project_Name\n",
    "    result[\"BFC\"] = row.BFC_Commit\n",
    "    result[\"BIC\"] = row.BIC_Commit\n",
    "    \n",
    "    # Retrieve some basic statistics first\n",
    "    result[\"Commits_Between\"] = diff_in_commits(directory, row.BFC_Commit, row.BIC_Commit)\n",
    "    result[\"Time_Between\"] = diff_in_time(directory, row.BFC_Commit, row.BIC_Commit)\n",
    "    result[\"BIC_Files_Edited\"], result[\"BIC_Lines_Added\"], result[\"BIC_Lines_Deleted\"] =\\\n",
    "        statistics(directory, row.BIC_Commit, row.Working_Commit)\n",
    "    result[\"BFC_Files_Edited\"], result[\"BFC_Lines_Added\"], result[\"BFC_Lines_Deleted\"] =\\\n",
    "        statistics(directory, row.BFC_Commit)\n",
    "    \n",
    "    # Retrieve advance statistics\n",
    "    bic_hunks = hunks_changed(directory, row.BIC_Commit, row.Working_Commit)\n",
    "    bic_scores = get_refactor_scores(bic_hunks)\n",
    "    bfc_hunks = hunks_changed(directory, row.BFC_Commit)\n",
    "    bfc_scores = get_refactor_scores(bfc_hunks)\n",
    "    result[\"BIC_Num_Hunks\"] = len(bic_hunks)\n",
    "    result[\"BFC_Num_Hunks\"] = len(bfc_hunks)\n",
    "    result[\"Min_Distance_Fix\"], result[\"Max_Distance_Fix\"], result[\"Mean_Distance_Fix\"] =\\\n",
    "        distances_to_fix(bic_hunks, bfc_hunks)\n",
    "    result[\"BIC_Is_Bug_Fix\"] = is_bug_fix(directory, row.BIC_Commit)\n",
    "    result[\"BIC_Is_Refactor\"] = is_refactor(directory, row.BIC_Commit, bic_scores)\n",
    "    result[\"BIC_Is_Feature_Enhancement\"] = is_feature_enhancement(bic_hunks, bic_scores)\n",
    "    result[\"BFC_Is_Refactor\"] = is_refactor(directory, row.BFC_Commit, bfc_scores)\n",
    "    result[\"BFC_Is_Feature_Enhancement\"] = is_feature_enhancement(bfc_hunks, bfc_scores)\n",
    "    result[\"Revert_Index\"] = revert_index(bfc_hunks, bic_hunks)\n",
    "\n",
    "    results = results.append(result, ignore_index=True)\n",
    "    results.to_csv(\"Intermediate_Result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project_Name                                      HikariCP\n",
       "BFC_Commit        5ea5688db367f880141e2b330e2ea7538aabc1e9\n",
       "BIC_Commit        b5967fc5a14b9a733be43a4771175eace8a856bd\n",
       "Working_Commit    1eb35356c5a72aa97e24e4a35f889ae945843a82\n",
       "Name: 347, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hikaricp-common/src/main/java/com/zaxxer/hikari/pool/BaseHikariPool.java\n",
      "\n",
      "hikaricp-common/src/test/java/com/zaxxer/hikari/TestConnectionTimeoutRetry.java\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = files_changed(directory, row.BFC_Commit, f\"{row.BFC_Commit}~1\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    output = subprocess.run(f\"git diff -U1000 {row.BFC_Commit}~1 {row.BFC_Commit} -- {file}\",\n",
    "                            shell=True, capture_output=True).stdout.decode(errors=\"Ignore\")\n",
    "    print(output)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RegMiner Empirical Studies.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
